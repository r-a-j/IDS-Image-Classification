{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "# External library imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATASET_DIR = 'F:\\\\Study\\\\TU Dortmund\\\\Industrial Data Science 2\\\\Code\\\\Reference\\\\CNN\\\\train'\n",
    "CATEGORIES = ['met', 'nichtmet']\n",
    "IMG_SIZE = 150  # Resize images to 150x150\n",
    "\n",
    "# Function to load and preprocess the images\n",
    "def load_data():\n",
    "    data = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATASET_DIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                img_array = cv2.imread(img_path)\n",
    "                img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return data\n",
    "\n",
    "# Load and shuffle data\n",
    "data = load_data()\n",
    "shuffle(data)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "# Normalize the data and reshape it\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) / 255.0\n",
    "y = np.array(y)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y = to_categorical(y, num_classes=len(CATEGORIES))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the data generator to the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(CATEGORIES), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate and print per-category accuracies\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=CATEGORIES)\n",
    "print(report)\n",
    "\n",
    "# Extract accuracy for each category\n",
    "report_dict = classification_report(y_true_classes, y_pred_classes, target_names=CATEGORIES, output_dict=True)\n",
    "category_accuracy = [report_dict[category]['precision'] for category in CATEGORIES]\n",
    "\n",
    "# Plot per-category accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(CATEGORIES, category_accuracy)\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy per Category')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model.save('metal_classifier_model_with_aug_2.keras')\n",
    "print(\"Model saved to metal_classifier_model_with_aug_2.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = load_model('metal_classifier_model_with_aug.keras')\n",
    "\n",
    "# Preprocess image for classification\n",
    "def preprocess_image(image_path, img_size=150):\n",
    "    img_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img_array is None:\n",
    "        raise ValueError(f\"Image not found or unable to load: {image_path}\")\n",
    "    img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "    img_array = img_array.reshape(-1, img_size, img_size, 1)\n",
    "    img_array = img_array / 255.0  # Normalize the image\n",
    "    return img_array\n",
    "\n",
    "# Classify the image as 'metal' or 'non-metal'\n",
    "def classify_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    categories = ['metal', 'non-metal']\n",
    "    return categories[predicted_class]\n",
    "\n",
    "# Preprocess image for segmentation\n",
    "def preprocess_image_for_segmentation(image_path, img_size=150):\n",
    "    img_array = cv2.imread(image_path)\n",
    "    if img_array is None:\n",
    "        raise ValueError(f\"Image not found or unable to load: {image_path}\")\n",
    "    img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "    return img_array\n",
    "\n",
    "# Segment the image and draw bounding boxes\n",
    "def segment_and_draw_bounding_box(image_path):\n",
    "    img_array = preprocess_image_for_segmentation(image_path)\n",
    "    \n",
    "    _, binary_img = cv2.threshold(cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter out smaller contours\n",
    "    contours = [contour for contour in contours if cv2.contourArea(contour) > 100]  # Adjust threshold as needed\n",
    "    \n",
    "    # Draw bounding boxes on the original image\n",
    "    img_color = img_array.copy()\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        color = (31, 119, 180)  # Default color for non-metal (hex: #1f77b4)\n",
    "        predicted_category = classify_image(image_path)\n",
    "        if predicted_category == 'metal':\n",
    "            color = (255, 127, 14)  # Color for metal (hex: #ff7f0e)\n",
    "        # Adjust bounding box coordinates based on contour dimensions\n",
    "        padding = 5  # Add some padding around the object\n",
    "        x1, y1 = max(0, x - padding), max(0, y - padding)\n",
    "        x2, y2 = min(img_array.shape[1], x + w + padding), min(img_array.shape[0], y + h + padding)\n",
    "        cv2.rectangle(img_color, (x1, y1), (x2, y2), color, 1)  # Thin bounding box\n",
    "        # Write category and confidence inside the bounding box\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        predictions = model.predict(preprocessed_image)\n",
    "        confidence = predictions[0][0 if predicted_category == 'metal' else 1] * 100  # Convert confidence to percentage\n",
    "        text = f'{predicted_category.capitalize()} ({confidence:.2f}%)'\n",
    "        font_scale = 0.4\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, 1)\n",
    "        text_x = x1 + 2\n",
    "        text_y = y1 + text_height + 2\n",
    "        cv2.putText(img_color, text, (text_x, text_y), font, font_scale, (0, 0, 0), 1)  # Black text\n",
    "    \n",
    "    # Display the image with bounding boxes and confidence\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Image path\n",
    "image_path = 'test/met (668).jpg'\n",
    "\n",
    "# Try segmenting and drawing bounding boxes\n",
    "try:    \n",
    "    segment_and_draw_bounding_box(image_path)\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
