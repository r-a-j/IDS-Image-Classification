{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths\n",
    "DATASET_DIR = '/home/user/cnn/data'\n",
    "CATEGORIES = ['met', 'nichtmet']\n",
    "IMG_SIZE = 640  # Ensure your system has enough memory for this size\n",
    "NEW_MODEL_PATH = '/home/user/cnn/model/metal_classifier_model_mobile.keras'\n",
    "RESULTS_DIR = '/home/user/cnn/results_' + datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Load and preprocess new dataset\n",
    "def load_data(dataset_dir, categories, img_size):\n",
    "    data = []\n",
    "    for category in categories:\n",
    "        path = os.path.join(dataset_dir, category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                img_array = cv2.imread(img_path)\n",
    "                img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "    return data\n",
    "\n",
    "data = load_data(DATASET_DIR, CATEGORIES, IMG_SIZE)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X = np.array([item[0] for item in data]) / 255.0\n",
    "y = np.array([item[1] for item in data])\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=len(CATEGORIES))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Load MobileNetV2 pre-trained model\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(CATEGORIES), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(os.path.join(RESULTS_DIR, 'best_model.keras'), save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Reduce the batch size if you encounter memory issues\n",
    "batch_size = 16\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, checkpoint, reduce_lr])\n",
    "\n",
    "# Load the best model\n",
    "model.load_weights(os.path.join(RESULTS_DIR, 'best_model.keras'))\n",
    "\n",
    "# Fine-tune the model (unfreeze some layers)\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "history_finetune = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                             epochs=100,\n",
    "                             validation_data=(X_val, y_val),\n",
    "                             callbacks=[early_stopping, checkpoint, reduce_lr])\n",
    "\n",
    "# Save the final model\n",
    "model.save(NEW_MODEL_PATH)\n",
    "\n",
    "# Save training information\n",
    "def save_training_info(history, results_dir, phase=\"initial\"):\n",
    "    # Plot training & validation accuracy and loss\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model Accuracy ({phase} phase)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(os.path.join(results_dir, f'{phase}_accuracy_plot.png'))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model Loss ({phase} phase)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(os.path.join(results_dir, f'{phase}_loss_plot.png'))\n",
    "\n",
    "    # Save history as text\n",
    "    with open(os.path.join(results_dir, f'{phase}_training_history.txt'), 'w') as f:\n",
    "        f.write(str(history.history))\n",
    "\n",
    "save_training_info(history, RESULTS_DIR, phase=\"initial\")\n",
    "save_training_info(history_finetune, RESULTS_DIR, phase=\"finetune\")\n",
    "\n",
    "print(f\"New model saved to {NEW_MODEL_PATH}\")\n",
    "print(f\"Training information saved to {RESULTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Code for Test Data Evaluation and Deployment:\n",
    "\n",
    "## 1. Evaluate Model on Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9486 - loss: 0.1352\n",
      "Test Accuracy: 94.09%\n",
      "Test Loss: 0.1577\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "# Note: Load test data here from another folder\n",
    "TEST_DIR = 'F:\\\\Study\\\\TU Dortmund\\\\Industrial Data Science 2\\\\Code\\\\Reference\\\\CNN\\\\train'\n",
    "test_data = load_data(TEST_DIR, CATEGORIES, IMG_SIZE)\n",
    "\n",
    "X_test = np.array([item[0] for item in test_data]) / 255.0\n",
    "y_test = np.array([item[1] for item in test_data])\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(CATEGORIES))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert Model for Mobile Deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Keras model to SavedModel format\n",
    "model.save('F:\\Study\\TU Dortmund\\Industrial Data Science 2\\Code\\Reference\\CNN\\results_20240702_155253\\best_model.keras')\n",
    "\n",
    "# Convert SavedModel to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('saved_model')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "TFLITE_MODEL_PATH = 'metal_classifier_model_mobile.tflite'\n",
    "with open(TFLITE_MODEL_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model converted and saved to {TFLITE_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "TFLITE_MODEL_PATH = 'F:\\\\Study\\\\TU Dortmund\\\\Industrial Data Science 2\\\\Code\\\\Reference\\\\CNN\\\\metal_classifier_model_mobile.tflite'\n",
    "with open(TFLITE_MODEL_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model converted and saved to {TFLITE_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Test the TensorFlow Lite Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare input data\n",
    "input_data = np.expand_dims(X_test[0], axis=0).astype(np.float32)  # Example with the first test image\n",
    "\n",
    "# Set the tensor to point to the input data to be inferred\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run the inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the results\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "predicted_label = np.argmax(output_data)\n",
    "print(f\"Predicted label: {CATEGORIES[predicted_label]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More improved enhanancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define paths\n",
    "DATASET_DIR = '/home/user/cnn/data'\n",
    "CATEGORIES = ['met', 'nichtmet']\n",
    "IMG_SIZE = 128\n",
    "NEW_MODEL_PATH = '/home/user/cnn/model/metal_classifier_model_mobile.keras'\n",
    "RESULTS_DIR = 'results_' + datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Load and preprocess new dataset\n",
    "def load_data(dataset_dir, categories, img_size):\n",
    "    data = []\n",
    "    for category in categories:\n",
    "        path = os.path.join(dataset_dir, category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                img_array = cv2.imread(img_path)\n",
    "                img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "    return data\n",
    "\n",
    "data = load_data(DATASET_DIR, CATEGORIES, IMG_SIZE)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X = np.array([item[0] for item in data]) / 255.0\n",
    "y = np.array([item[1] for item in data])\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=len(CATEGORIES))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Load MobileNetV2 pre-trained model\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# Add custom layers on top of base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(CATEGORIES), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(os.path.join(RESULTS_DIR, 'best_model.keras'), save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, checkpoint])\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Final Validation Loss: {val_loss:.4f}, Final Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "# Print classification report\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes, target_names=CATEGORIES))\n",
    "\n",
    "# Save the final model\n",
    "model.save(NEW_MODEL_PATH)\n",
    "\n",
    "# Save training information\n",
    "def save_training_info(history, results_dir, phase=\"initial\"):\n",
    "    # Plot training & validation accuracy and loss\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model Accuracy ({phase} phase)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(os.path.join(results_dir, f'{phase}_accuracy_plot.png'))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model Loss ({phase} phase)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(os.path.join(results_dir, f'{phase}_loss_plot.png'))\n",
    "\n",
    "    # Save history as text\n",
    "    with open(os.path.join(results_dir, f'{phase}_training_history.txt'), 'w') as f:\n",
    "        f.write(str(history.history))\n",
    "\n",
    "save_training_info(history, RESULTS_DIR, phase=\"initial\")\n",
    "\n",
    "print(f\"New model saved to {NEW_MODEL_PATH}\")\n",
    "print(f\"Training information saved to {RESULTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the best model for evaluation\n",
    "model = tf.keras.models.load_model('F:\\\\Study\\\\TU Dortmund\\\\Industrial Data Science 2\\\\Code\\\\Reference\\\\CNN\\\\results_20240702_163204\\\\best_model.keras')\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "# Get predictions for confusion matrix and classification report\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=CATEGORIES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Final Validation Loss: {val_loss:.4f}, Final Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "# Print classification report\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes, target_names=CATEGORIES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train new for mobile images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, average_precision_score\n",
    "\n",
    "# Enable mixed precision\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Define paths\n",
    "DATASET_DIR = '/home/user/unet/cnn/data'\n",
    "CATEGORIES = ['met', 'nichtmet']\n",
    "IMG_SIZE = 512  # Reduced image size\n",
    "\n",
    "# Function to load and preprocess the images\n",
    "def load_data():\n",
    "    data = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATASET_DIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return data\n",
    "\n",
    "# Load and shuffle data\n",
    "data = load_data()\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = np.array([item[0] for item in data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1) / 255.0\n",
    "y = np.array([item[1] for item in data])\n",
    "\n",
    "# One-hot encode the labels\n",
    "y = to_categorical(y, num_classes=len(CATEGORIES))\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the data generator to the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(len(CATEGORIES), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Model checkpoint callback\n",
    "checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Reduce learning rate callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-4)\n",
    "\n",
    "# Train the model with batch size 2\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=2),\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, checkpoint, reduce_lr])\n",
    "\n",
    "# Load the best model\n",
    "model.load_weights('best_model.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=CATEGORIES)\n",
    "print(report)\n",
    "\n",
    "# Precision and recall graph\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(len(CATEGORIES)):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_pred[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_pred[:, i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(CATEGORIES)):\n",
    "    plt.plot(recall[i], precision[i], lw=2, label=f'Precision-recall curve of class {CATEGORIES[i]} (AP={average_precision[i]:0.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "model.save('metal_classifier_model_mobile_from_scratch.keras')\n",
    "print(\"Model saved to metal_classifier_model_mobile_from_scratch.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
